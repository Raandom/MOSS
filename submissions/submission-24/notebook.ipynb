{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cow_OZ5Q9CEu",
        "outputId": "754974f9-55a8-4a60-a7f0-f983994ce86c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typed-argument-parser\n",
            "  Downloading typed_argument_parser-1.10.1-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from typed-argument-parser) (0.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from typed-argument-parser) (24.2)\n",
            "Collecting typing-inspect>=0.7.1 (from typed-argument-parser)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.7.1->typed-argument-parser)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.7.1->typed-argument-parser) (4.13.2)\n",
            "Downloading typed_argument_parser-1.10.1-py3-none-any.whl (30 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, typed-argument-parser\n",
            "Successfully installed mypy-extensions-1.1.0 typed-argument-parser-1.10.1 typing-inspect-0.9.0\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.6.0\n",
            "Collecting sb3_contrib\n",
            "  Downloading sb3_contrib-2.6.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: stable_baselines3<3.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from sb3_contrib) (2.6.0)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3_contrib) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3_contrib) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3_contrib) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3_contrib) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3_contrib) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3_contrib) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib) (3.0.2)\n",
            "Downloading sb3_contrib-2.6.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sb3_contrib\n",
            "Successfully installed sb3_contrib-2.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install typed-argument-parser\n",
        "!pip install stable-baselines3\n",
        "!pip install sb3_contrib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "import itertools\n",
        "from typing import Dict, Literal, Optional, List\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from sb3_contrib import MaskablePPO\n",
        "from sb3_contrib.common.maskable.callbacks import MaskableEvalCallback\n",
        "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.env_util import SubprocVecEnv, make_vec_env, DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback"
      ],
      "metadata": {
        "id": "-ek1-XXv9lm5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure model and training parameters.\n",
        "\n",
        "class Args(object):\n",
        "    no_wandb: bool = False\n",
        "    total_timesteps: int = 4_000_000\n",
        "    seed: int = random.randint(0, 2**32 - 1)\n",
        "    n_envs: int = 32\n",
        "    device: Literal['cpu', 'mps', 'cuda'] = 'cuda'\n",
        "    feature_extractor: Literal['none', 'tfh_small', 'tfh_big', 'tf', 'tfh_fast'] = 'tfh_fast'\n",
        "    env_num_inserts: int = 6\n",
        "    env_num_deletes: int = 6\n",
        "    env_max_tree_values: int = 24\n",
        "    env_max_values_per_node: int = 4\n",
        "    checkpoint_callback_freq: int = 50_000\n",
        "    s_net_arch: Dict[str, list[int]] = {'pi': [512, 512], 'vf': [512, 512]}\n",
        "    s_transformer_features_dim: int = 64\n",
        "    s_transformer_num_layers: int = 2\n",
        "    s_transformer_nhead: int = 2\n",
        "    s_n_epochs: int = 10\n",
        "    s_learning_rate: float = 1e-4\n",
        "    s_entropy_coef: int = 0\n",
        "    s_n_eval_episodes: int = 10_000\n",
        "    s_eval_freq: int = 50_000\n",
        "    s_n_seeds: int = 40\n",
        "    s_batch_size: int = 512\n",
        "    s_n_steps: int =  1000\n",
        "\n",
        "args = Args()"
      ],
      "metadata": {
        "id": "EbtMQuEg9ECu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# B+Tree adapted from https://gist.github.com/benben233/2c8a2a8ab44a7beabad0df1b6658232e\n",
        "# In the calculation functions, it contains the logic to compute the cost of an executed operation\n",
        "\n",
        "class Node(object):\n",
        "    \"\"\"Base node object. It should be an index node\n",
        "    Each node stores keys and children.\n",
        "\n",
        "    Attributes:\n",
        "        parent\n",
        "        cost_dict\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cost_dict: dict, parent=None):\n",
        "        \"\"\"Child nodes are stored in values. Parent nodes simply act as a medium to traverse the tree.\n",
        "        :type parent: Node\"\"\"\n",
        "        self.keys: list = []\n",
        "        self.values: list[Node] = []\n",
        "        self.parent: Node = parent\n",
        "        self.cost_dict: dict = cost_dict\n",
        "\n",
        "    def index(self, key):\n",
        "        \"\"\"Return the index where the key should be.\n",
        "        :type key: str\n",
        "        \"\"\"\n",
        "        for i, item in enumerate(self.keys):\n",
        "            if key < item:\n",
        "                return i\n",
        "\n",
        "        return len(self.keys)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.values[self.index(item)]\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        i = self.index(key)\n",
        "        self.keys[i:i] = [key]\n",
        "        self.values.pop(i)\n",
        "        self.values[i:i] = value\n",
        "\n",
        "    def split(self):\n",
        "        \"\"\"Splits the node into two and stores them as child nodes.\n",
        "        extract a pivot from the child to be inserted into the keys of the parent.\n",
        "        @:return key and two children\n",
        "        \"\"\"\n",
        "        self.cost_dict[\"splits\"] += 1\n",
        "        self.cost_dict[\"parent_splits\"] += 1\n",
        "\n",
        "        left = Node(cost_dict=self.cost_dict, parent=self.parent)\n",
        "\n",
        "        mid = len(self.keys) // 2\n",
        "\n",
        "        left.keys = self.keys[:mid]\n",
        "        left.values = self.values[: mid + 1]\n",
        "        for child in left.values:\n",
        "            child.parent = left\n",
        "\n",
        "        key = self.keys[mid]\n",
        "        self.keys = self.keys[mid + 1 :]\n",
        "        self.values = self.values[mid + 1 :]\n",
        "\n",
        "        return key, [left, self]\n",
        "\n",
        "    def __delitem__(self, key):\n",
        "        i = self.index(key)\n",
        "        del self.values[i]\n",
        "        if i < len(self.keys):\n",
        "            del self.keys[i]\n",
        "        else:\n",
        "            del self.keys[i - 1]\n",
        "\n",
        "    def fusion(self):\n",
        "        self.cost_dict[\"fusions\"] += 1\n",
        "        self.cost_dict[\"parent_fusions\"] += 1\n",
        "\n",
        "        index = self.parent.index(self.keys[0])\n",
        "        # merge this node with the next node\n",
        "        if index < len(self.parent.keys):\n",
        "            next_node: Node = self.parent.values[index + 1]\n",
        "            next_node.keys[0:0] = self.keys + [self.parent.keys[index]]\n",
        "            for child in self.values:\n",
        "                child.parent = next_node\n",
        "            next_node.values[0:0] = self.values\n",
        "        else:  # If self is the last node, merge with prev\n",
        "            prev: Node = self.parent.values[-2]\n",
        "            prev.keys += [self.parent.keys[-1]] + self.keys\n",
        "            for child in self.values:\n",
        "                child.parent = prev\n",
        "            prev.values += self.values\n",
        "\n",
        "    def borrow_key(self, minimum: int):\n",
        "        index = self.parent.index(self.keys[0])\n",
        "        if index < len(self.parent.keys):\n",
        "            next_node: Node = self.parent.values[index + 1]\n",
        "            if len(next_node.keys) > minimum:\n",
        "                self.keys += [self.parent.keys[index]]\n",
        "\n",
        "                borrow_node = next_node.values.pop(0)\n",
        "                borrow_node.parent = self\n",
        "                self.values += [borrow_node]\n",
        "                self.parent.keys[index] = next_node.keys.pop(0)\n",
        "                return True\n",
        "        elif index != 0:\n",
        "            prev: Node = self.parent.values[index - 1]\n",
        "            if len(prev.keys) > minimum:\n",
        "                self.keys[0:0] = [self.parent.keys[index - 1]]\n",
        "\n",
        "                borrow_node = prev.values.pop()\n",
        "                borrow_node.parent = self\n",
        "                self.values[0:0] = [borrow_node]\n",
        "                self.parent.keys[index - 1] = prev.keys.pop()\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "class Leaf(Node):\n",
        "    def __init__(self, cost_dict: dict, parent=None, prev_node=None, next_node=None):\n",
        "        \"\"\"\n",
        "        Create a new leaf in the leaf link\n",
        "        :type prev_node: Leaf\n",
        "        :type next_node: Leaf\n",
        "        \"\"\"\n",
        "        super(Leaf, self).__init__(cost_dict, parent)\n",
        "        self.next: Leaf = next_node\n",
        "        if next_node is not None:\n",
        "            next_node.prev = self\n",
        "        self.prev: Leaf = prev_node\n",
        "        if prev_node is not None:\n",
        "            prev_node.next = self\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.values[self.keys.index(item)]\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        i = self.index(key)\n",
        "        if key not in self.keys:\n",
        "            self.keys[i:i] = [key]\n",
        "            self.values[i:i] = [value]\n",
        "        else:\n",
        "            self.values[i - 1] = value\n",
        "\n",
        "    def split(self):\n",
        "        self.cost_dict[\"splits\"] += 1\n",
        "\n",
        "        left = Leaf(\n",
        "            cost_dict=self.cost_dict,\n",
        "            parent=self.parent,\n",
        "            prev_node=self.prev,\n",
        "            next_node=self,\n",
        "        )\n",
        "        mid = len(self.keys) // 2\n",
        "\n",
        "        left.keys = self.keys[:mid]\n",
        "        left.values = self.values[:mid]\n",
        "\n",
        "        self.keys: list = self.keys[mid:]\n",
        "        self.values: list = self.values[mid:]\n",
        "\n",
        "        # When the leaf node is split, set the parent key to the left-most key of the right child node.\n",
        "        return self.keys[0], [left, self]\n",
        "\n",
        "    def __delitem__(self, key):\n",
        "        i = self.keys.index(key)\n",
        "        del self.keys[i]\n",
        "        del self.values[i]\n",
        "\n",
        "    def fusion(self):\n",
        "        self.cost_dict[\"fusions\"] += 1\n",
        "\n",
        "        if self.next is not None and self.next.parent == self.parent:\n",
        "            self.next.keys[0:0] = self.keys\n",
        "            self.next.values[0:0] = self.values\n",
        "        else:\n",
        "            self.prev.keys += self.keys\n",
        "            self.prev.values += self.values\n",
        "\n",
        "        if self.next is not None:\n",
        "            self.next.prev = self.prev\n",
        "        if self.prev is not None:\n",
        "            self.prev.next = self.next\n",
        "\n",
        "    def borrow_key(self, minimum: int):\n",
        "        index = self.parent.index(self.keys[0])\n",
        "        if index < len(self.parent.keys) and len(self.next.keys) > minimum:\n",
        "            self.keys += [self.next.keys.pop(0)]\n",
        "            self.values += [self.next.values.pop(0)]\n",
        "            self.parent.keys[index] = self.next.keys[0]\n",
        "            return True\n",
        "        elif index != 0 and len(self.prev.keys) > minimum:\n",
        "            self.keys[0:0] = [self.prev.keys.pop()]\n",
        "            self.values[0:0] = [self.prev.values.pop()]\n",
        "            self.parent.keys[index - 1] = self.keys[0]\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "class BPlusTree(object):\n",
        "    \"\"\"B+ tree object, consisting of nodes.\n",
        "\n",
        "    Nodes will automatically be split into two once it is full. When a split occurs, a key will\n",
        "    'float' upwards and be inserted into the parent node to act as a pivot.\n",
        "\n",
        "    Attributes:\n",
        "        maximum (int): The maximum number of keys each node can hold.\n",
        "    \"\"\"\n",
        "\n",
        "    root: Node\n",
        "    cost_dict: dict\n",
        "\n",
        "    def __init__(self, maximum=4):\n",
        "        self.cost_dict = {\n",
        "            \"splits\": 0,\n",
        "            \"parent_splits\": 0,\n",
        "            \"fusions\": 0,\n",
        "            \"parent_fusions\": 0,\n",
        "        }\n",
        "        self.root = Leaf(cost_dict=self.cost_dict)\n",
        "        self.maximum: int = maximum if maximum > 2 else 2\n",
        "        self.minimum: int = self.maximum // 2\n",
        "        self.depth = 0\n",
        "\n",
        "    def find(self, key) -> Leaf:\n",
        "        \"\"\"find the leaf\n",
        "\n",
        "        Returns:\n",
        "            Leaf: the leaf which should have the key\n",
        "        \"\"\"\n",
        "        node = self.root\n",
        "        # Traverse tree until leaf node is reached.\n",
        "        while type(node) is not Leaf:\n",
        "            node = node[key]\n",
        "\n",
        "        return node\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.find(item)[item]\n",
        "\n",
        "    def query(self, key):\n",
        "        \"\"\"Returns a value for a given key, and None if the key does not exist.\"\"\"\n",
        "        leaf = self.find(key)\n",
        "        return leaf[key] if key in leaf.keys else None\n",
        "\n",
        "    def change(self, key, value):\n",
        "        \"\"\"change the value\n",
        "\n",
        "        Returns:\n",
        "            (bool,Leaf): the leaf where the key is. return False if the key does not exist\n",
        "        \"\"\"\n",
        "        leaf = self.find(key)\n",
        "        if key not in leaf.keys:\n",
        "            return False, leaf\n",
        "        else:\n",
        "            leaf[key] = value\n",
        "            return True, leaf\n",
        "\n",
        "    def __setitem__(self, key, value, leaf=None):\n",
        "        \"\"\"Inserts a key-value pair after traversing to a leaf node. If the leaf node is full, split\n",
        "        the leaf node into two.\n",
        "        \"\"\"\n",
        "        if leaf is None:\n",
        "            leaf = self.find(key)\n",
        "        leaf[key] = value\n",
        "        if len(leaf.keys) > self.maximum:\n",
        "            self.insert_index(*leaf.split())\n",
        "\n",
        "    def insert(self, key, value):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            (bool,Leaf): the leaf where the key is inserted. return False if already has same key\n",
        "        \"\"\"\n",
        "        leaf = self.find(key)\n",
        "        if key in leaf.keys:\n",
        "            return False, leaf\n",
        "        else:\n",
        "            self.__setitem__(key, value, leaf)\n",
        "            return True, leaf\n",
        "\n",
        "    def insert_index(self, key, values: list[Node]):\n",
        "        \"\"\"For a parent and child node,\n",
        "        Insert the values from the child into the values of the parent.\"\"\"\n",
        "        parent = values[1].parent\n",
        "        if parent is None:\n",
        "            values[0].parent = values[1].parent = self.root = Node(\n",
        "                cost_dict=self.cost_dict\n",
        "            )\n",
        "            self.depth += 1\n",
        "            self.root.keys = [key]\n",
        "            self.root.values = values\n",
        "            return\n",
        "\n",
        "        parent[key] = values\n",
        "        # If the node is full, split the  node into two.\n",
        "        if len(parent.keys) > self.maximum:\n",
        "            self.insert_index(*parent.split())\n",
        "        # Once a leaf node is split, it consists of a internal node and two leaf nodes.\n",
        "        # These need to be re-inserted back into the tree.\n",
        "\n",
        "    def delete(self, key, node: Node = None):\n",
        "        if node is None:\n",
        "            node = self.find(key)\n",
        "        del node[key]\n",
        "\n",
        "        if len(node.keys) < self.minimum:\n",
        "            if node == self.root:\n",
        "                if len(self.root.keys) == 0 and len(self.root.values) > 0:\n",
        "                    self.root = self.root.values[0]\n",
        "                    self.root.parent = None\n",
        "                    self.depth -= 1\n",
        "                return\n",
        "\n",
        "            elif not node.borrow_key(self.minimum):\n",
        "                node.fusion()\n",
        "                self.delete(key, node.parent)\n",
        "\n",
        "    def show(self, node=None, file=None, _prefix=\"\", _last=True):\n",
        "        \"\"\"Prints the keys at each level.\"\"\"\n",
        "        if node is None:\n",
        "            node = self.root\n",
        "        print(_prefix, \"`- \" if _last else \"|- \", node.keys, sep=\"\", file=file)\n",
        "        _prefix += \"   \" if _last else \"|  \"\n",
        "\n",
        "        if type(node) is Node:\n",
        "            # Recursively print the key of child nodes (if these exist).\n",
        "            for i, child in enumerate(node.values):\n",
        "                _last = i == len(node.values) - 1\n",
        "                self.show(child, file, _prefix, _last)\n",
        "\n",
        "    def output(self):\n",
        "        return tuple(self.cost_dict.values()), self.depth\n",
        "\n",
        "    def readfile(self, reader):\n",
        "        i = 0\n",
        "        for i, line in enumerate(reader):\n",
        "            s = line.decode().split(maxsplit=1)\n",
        "            self[s[0]] = s[1]\n",
        "            if i % 1000 == 0:\n",
        "                print(\"Insert \" + str(i) + \"items\")\n",
        "        return i + 1\n",
        "\n",
        "    def leftmost_leaf(self) -> Leaf:\n",
        "        node = self.root\n",
        "        while type(node) is not Leaf:\n",
        "            node = node.values[0]\n",
        "        return node\n",
        "\n",
        "    def get_obs_space_representation(self, max_depth):\n",
        "        \"\"\"\n",
        "        Returns a 1D array representation of the tree:\n",
        "        - Keys in each node are padded with zeros to `maximum` keys.\n",
        "        - The entire structure is padded with zeros to account for the maximum possible nodes at each level.\n",
        "        \"\"\"\n",
        "\n",
        "        max_depth += 1 # Add 1 to account for the root node\n",
        "        levels = [[] for _ in range(max_depth)]\n",
        "\n",
        "        def dfs(node: Node, depth: int):\n",
        "            if depth == max_depth:\n",
        "                return\n",
        "\n",
        "            level = levels[depth]\n",
        "\n",
        "            if node is None:\n",
        "                level += [0] * self.maximum\n",
        "                children = []\n",
        "            else:\n",
        "                level += node.keys.copy() + [0] * (self.maximum - len(node.keys))\n",
        "                assert len(level) % self.maximum == 0\n",
        "\n",
        "                if type(node) is Leaf:\n",
        "                    children = []\n",
        "                else:\n",
        "                    children = node.values.copy()\n",
        "\n",
        "\n",
        "            while len(children) < self.maximum + 1:\n",
        "                children.append(None)\n",
        "\n",
        "            assert len(children) == self.maximum + 1\n",
        "\n",
        "            for child in children:\n",
        "                dfs(child, depth + 1)\n",
        "\n",
        "        # Start traversal from the root\n",
        "        dfs(self.root, 0)\n",
        "\n",
        "        # Make sure the layers are filled correctly\n",
        "        prev_nodes = 1\n",
        "        for level in levels[1:]:\n",
        "            cur_nodes = prev_nodes * (self.maximum + 1)\n",
        "            assert len(level) == cur_nodes * self.maximum\n",
        "            prev_nodes = cur_nodes\n",
        "\n",
        "        flattened_representation = list(itertools.chain(*levels))\n",
        "        return np.array(flattened_representation).flatten()\n",
        "\n",
        "    def get_obs_space_feature_representation(self, max_depth):\n",
        "        \"\"\"\n",
        "        Returns a 1D array representation of the tree with feature engineering:\n",
        "        - Each node is represented by its minimum key, maximum key, and fill percentage.\n",
        "        - The structure is padded with zeros to account for the maximum possible nodes at each level.\n",
        "        \"\"\"\n",
        "\n",
        "        max_depth += 1  # Add 1 to account for the root node\n",
        "        levels = [[] for _ in range(max_depth)]\n",
        "\n",
        "        def dfs(node: Node, depth: int):\n",
        "            if depth == max_depth:\n",
        "                return\n",
        "\n",
        "            level = levels[depth]\n",
        "\n",
        "            if node is None:\n",
        "                level += [0, 0, 0]\n",
        "                children = []\n",
        "            else:\n",
        "                min_key = min(node.keys) if node.keys else 0\n",
        "                max_key = max(node.keys) if node.keys else 0\n",
        "                fill_percentage = len(node.keys) / self.maximum\n",
        "\n",
        "                level += [min_key, max_key, fill_percentage]\n",
        "\n",
        "                if isinstance(node, Leaf):\n",
        "                    children = []\n",
        "                else:\n",
        "                    children = node.values.copy()\n",
        "\n",
        "            while len(children) < self.maximum + 1:\n",
        "                children.append(None)\n",
        "\n",
        "            assert len(children) == self.maximum + 1\n",
        "\n",
        "            for child in children:\n",
        "                dfs(child, depth + 1)\n",
        "\n",
        "        dfs(self.root, 0)\n",
        "\n",
        "        # Make sure the layers are filled correctly\n",
        "        prev_nodes = 1\n",
        "        for level in levels[1:]:\n",
        "            cur_nodes = prev_nodes * (self.maximum + 1)\n",
        "            assert len(level) == cur_nodes * 3  # **3 features per node (min, max, fill percentage).**\n",
        "            prev_nodes = cur_nodes\n",
        "\n",
        "        flattened_representation = list(itertools.chain(*levels))\n",
        "        return np.array(flattened_representation).flatten()\n",
        "\n",
        "\n",
        "    def reset_cost_dict(self):\n",
        "        for key in self.cost_dict.keys():\n",
        "            self.cost_dict[key] = 0\n",
        "\n",
        "    def calculate_reward(self):\n",
        "        cost_factors = {\n",
        "            \"splits\": 2,\n",
        "            \"parent_splits\": 1,\n",
        "            \"fusions\": 2,\n",
        "            \"parent_fusions\": 1,\n",
        "        }\n",
        "        reward = 0\n",
        "        for key in self.cost_dict.keys():\n",
        "            reward += cost_factors[key] * self.cost_dict[key]\n",
        "        self.reset_cost_dict()\n",
        "        return reward\n",
        "\n",
        "\n",
        "\n",
        "def calculate_length_max_depth_of_tree(max_tree_values, max_keys):\n",
        "    \"\"\"\n",
        "    Calculate the length of the observation space representation.\n",
        "    \"\"\"\n",
        "    # max_depth = calculate_max_depth(num_inserts,num_values,max_keys)\n",
        "\n",
        "    max_depth = 1 + np.log(max_tree_values) / (np.log(max_keys + 1))\n",
        "    max_depth = int(max_depth)\n",
        "    #print(\"Max Depth:\", max_depth)\n",
        "\n",
        "    total_keys = 3\n",
        "    prev_nodes = 1\n",
        "    for level in range(1, max_depth+1):\n",
        "        cur_nodes = prev_nodes * (max_keys + 1)\n",
        "        total_keys += cur_nodes * 3\n",
        "\n",
        "        values_in_level = cur_nodes * 3\n",
        "        prev_nodes = cur_nodes\n",
        "    #print(\"Total Keys:\", total_keys)\n",
        "    #print(\"Values in Level:\", values_in_level)\n",
        "    return  total_keys, max_depth\n",
        "\n",
        "\n",
        "def printTree(tree):\n",
        "    current_node = tree.root\n",
        "    if current_node is not None:\n",
        "        print(current_node.values)\n",
        "        print(current_node.keys)\n",
        "        print(current_node.nextKey)\n",
        "        print(current_node.parent)\n",
        "        print(current_node.check_leaf)\n",
        "        print(\"\\n\")\n",
        "        if not current_node.check_leaf:\n",
        "            for i, item in enumerate(current_node.keys):\n",
        "                printTree(current_node.keys[i])"
      ],
      "metadata": {
        "id": "3gAXM5C49PBH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The training environment which uses the previously defined B-tree\n",
        "# The important pieces are contained in the step function.\n",
        "\n",
        "class BScheduler(gym.Env):\n",
        "    def __init__(self, args: Args = Args(), render_mode: Optional[str] = None):\n",
        "        self.num_inserts = args.env_num_inserts\n",
        "        self.num_deletes =  args.env_num_deletes\n",
        "        self.num_operations = self.num_inserts + self.num_deletes\n",
        "        self.max_tree_values = args.env_max_tree_values\n",
        "        self.max_values_per_node = args.env_max_values_per_node\n",
        "        self.action_space = spaces.Discrete(self.num_operations)\n",
        "        self.low = -2\n",
        "        self.high = self.max_tree_values + self.num_operations\n",
        "        self.len_tree_obs_space, self.max_possible_tree_depth = calculate_length_max_depth_of_tree(\n",
        "            self.max_tree_values, self.max_values_per_node\n",
        "        )\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=self.low,\n",
        "            high=self.high,\n",
        "            shape=(self.len_tree_obs_space + self.num_operations,),\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "        self.tree = None\n",
        "        self.tree_representation = None\n",
        "        self.inserts = None\n",
        "        self.deletes = None\n",
        "        self.rng = np.random.default_rng(None)\n",
        "\n",
        "\n",
        "    def _get_obs(self):\n",
        "        self.tree_representation = self.tree.get_obs_space_feature_representation(\n",
        "            self.max_possible_tree_depth\n",
        "        )\n",
        "        assert len(self.tree_representation) == self.len_tree_obs_space\n",
        "        assert self.tree_representation[-1] == 0\n",
        "        return np.concatenate([self.operations, self.tree_representation], dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
        "        super().reset(seed=seed)\n",
        "        if seed is not None:\n",
        "            self.rng = np.random.default_rng(seed=seed)\n",
        "        self.tree = BPlusTree(maximum=self.max_values_per_node)\n",
        "        self.tree_numbers = self.rng.choice(\n",
        "            a=np.arange(1, self.high), size=self.max_tree_values + self.num_inserts, replace=False\n",
        "        )\n",
        "        inserts = self.tree_numbers[self.max_tree_values:]\n",
        "        for i in range(self.max_tree_values - self.num_inserts):\n",
        "            self.tree.insert(self.tree_numbers[i], self.tree_numbers[i])\n",
        "\n",
        "        deletes = self.rng.choice(\n",
        "            self.tree_numbers[:self.num_deletes], self.num_deletes, replace=False\n",
        "        )\n",
        "\n",
        "        sorted_deletes = np.sort(deletes)\n",
        "        sorted_inserts = np.sort(inserts)\n",
        "        self.tree.calculate_reward()  # to reset counters\n",
        "        self.operations = np.concatenate([sorted_inserts, sorted_deletes])\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        info = {}\n",
        "        truncated = False\n",
        "        terminated = False\n",
        "        reward = 0\n",
        "        # Check for valid action choices\n",
        "        operation = self.operations[action]\n",
        "        if operation == -1:\n",
        "            print(\"operation\", operation)\n",
        "            print(\"operations\", self.operations)\n",
        "            raise \"This should not happen if you use MaskablePPO\"\n",
        "\n",
        "        # If an action is contained in the first half of the actions, it is an insert operation\n",
        "        elif action < self.num_operations // 2:\n",
        "            self.tree.insert(operation, operation)\n",
        "        else:\n",
        "            self.tree.delete(operation)\n",
        "        self.operations[action] = -1\n",
        "\n",
        "        # Once the todo-list is empty, the process finishes\n",
        "        if (self.operations == -1).all():\n",
        "            terminated = True\n",
        "\n",
        "        observation = self._get_obs()\n",
        "\n",
        "        # The tree library contains the logic to compute the cost of the last executed operation\n",
        "        reward = -1 * self.tree.calculate_reward()\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "    def action_masks(self) -> List[bool]:\n",
        "        ret = self.operations != -1\n",
        "        return ret\n",
        "\n",
        "\n",
        "gym.register(\n",
        "    id=\"BScheduler-v0\",\n",
        "    entry_point=BScheduler,\n",
        ")"
      ],
      "metadata": {
        "id": "I1h1kCPA9WJs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OptimizedHierarchicalBPlusFeatureExtractor(BaseFeaturesExtractor):\n",
        "    \"\"\"\n",
        "    The feature extractor, which contains the main logic of the hierarchical model described in the text.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 observation_space: gym.spaces.Box,\n",
        "                 feature_dim: int = 256,\n",
        "                 values_per_node: int = 4,\n",
        "                 num_ops: int = 6,\n",
        "                 num_heads: int = 4,\n",
        "                 dropout: float = 0.1,\n",
        "                 max_levels: int = 10):\n",
        "        super(OptimizedHierarchicalBPlusFeatureExtractor, self).__init__(\n",
        "            observation_space,\n",
        "            feature_dim + num_ops\n",
        "        )\n",
        "        self.features_per_node = 3\n",
        "        self.values_per_node = values_per_node\n",
        "        self.children_per_node = values_per_node + 1\n",
        "        self.num_ops = num_ops\n",
        "        self.feature_dim = feature_dim\n",
        "        self.max_levels = max_levels\n",
        "        self.debug = False\n",
        "\n",
        "        self.level_structure = self._compute_level_structure(observation_space.shape)\n",
        "\n",
        "        # By default, a TransformerEncoderLayer is used for the computation. It is shared among all levels of the tree.\n",
        "        self.transformer = nn.TransformerEncoderLayer(\n",
        "            d_model=feature_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=feature_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.linear = nn.Linear(feature_dim, feature_dim)\n",
        "        self.leaf_embedding = nn.Linear(self.features_per_node, feature_dim)\n",
        "        self.node_combiner = nn.Linear(feature_dim * self.children_per_node + self.features_per_node, feature_dim)\n",
        "        self.level_embeddings = nn.Parameter(torch.randn(max_levels, 1, feature_dim))\n",
        "        self.level_norm = nn.LayerNorm(feature_dim)\n",
        "        self.node_norm = nn.LayerNorm(feature_dim * self.children_per_node + self.features_per_node)\n",
        "\n",
        "    def _compute_level_structure(self, obs):\n",
        "        \"\"\"\n",
        "        Pre-compute the structure of each level in the tree.\n",
        "        Calculate leaf start index and propagate upwards to get all index ranges for all nodes.\n",
        "        \"\"\"\n",
        "        num_levels = 0\n",
        "        idx = 1\n",
        "        obs_without_actions = obs[0] - self.num_ops\n",
        "        # Determine the number of levels and leaf start index\n",
        "        while idx < obs_without_actions:\n",
        "            if idx * self.children_per_node > obs_without_actions:\n",
        "                break\n",
        "            idx *= self.children_per_node\n",
        "            num_levels += 1\n",
        "\n",
        "        level_structure = []\n",
        "        current_value_end = obs_without_actions\n",
        "\n",
        "        for level in range(num_levels, -1, -1):\n",
        "            nodes_this_level = idx if level == num_levels else idx // (self.children_per_node ** (num_levels - level))\n",
        "            parent_nodes = nodes_this_level // self.children_per_node\n",
        "\n",
        "            value_start_idx = current_value_end - nodes_this_level * self.features_per_node\n",
        "\n",
        "            level_info = {\n",
        "                'num_nodes': nodes_this_level,\n",
        "                'num_parents': parent_nodes,\n",
        "                'value_start_idx': value_start_idx,\n",
        "                'values_per_level': nodes_this_level * self.features_per_node,\n",
        "                'value_end_idx': current_value_end\n",
        "            }\n",
        "\n",
        "            level_structure.append(level_info)\n",
        "            current_value_end = value_start_idx\n",
        "\n",
        "        return level_structure\n",
        "\n",
        "\n",
        "    def _get_empty_mask(self, node_values):\n",
        "        empty = node_values[..., 0] == 0\n",
        "        return empty\n",
        "\n",
        "    def process_level(self, level_info, current_embeddings, tree_data, level_idx):\n",
        "        # Parse one level of the tree using the data stored in tree_data\n",
        "        batch_size = current_embeddings.shape[0]\n",
        "        num_parents = level_info['num_parents']\n",
        "\n",
        "        if num_parents == 0:  # root node have to pass\n",
        "            return current_embeddings\n",
        "\n",
        "\n",
        "        parent_values_start = level_info['value_start_idx']\n",
        "        parent_values = tree_data[:, parent_values_start - num_parents * self.features_per_node:parent_values_start]\n",
        "        parent_values = parent_values.view(batch_size, num_parents, self.features_per_node)\n",
        "        empty_mask = self._get_empty_mask(parent_values)\n",
        "\n",
        "        output_embeddings = torch.zeros(\n",
        "            batch_size, num_parents, self.feature_dim,\n",
        "            device=current_embeddings.device\n",
        "        )\n",
        "\n",
        "        if (~empty_mask).any():\n",
        "            non_empty_indices = torch.nonzero(~empty_mask)\n",
        "            non_empty_parents = parent_values[~empty_mask]\n",
        "\n",
        "\n",
        "            grouped_children = current_embeddings.view(batch_size, -1, self.children_per_node, self.feature_dim)\n",
        "            non_empty_children = grouped_children[non_empty_indices[:, 0], non_empty_indices[:, 1]]\n",
        "\n",
        "            children_flat = non_empty_children.view(-1, self.children_per_node * self.feature_dim)\n",
        "\n",
        "            combined = torch.cat([children_flat, non_empty_parents], dim=1)\n",
        "            #combined = self.node_norm(combined)\n",
        "            parent_embeddings = self.node_combiner(combined)\n",
        "\n",
        "            level_embedding = self.level_embeddings[level_idx].expand(len(parent_embeddings), -1)\n",
        "            parent_embeddings = parent_embeddings + level_embedding\n",
        "            parent_embeddings = self.level_norm(parent_embeddings)\n",
        "\n",
        "            transformed = self.transformer(parent_embeddings.unsqueeze(1)).squeeze(1)\n",
        "            #transformed = self.linear(parent_embeddings.unsqueeze(1)).squeeze(1) # linear version\n",
        "            output_embeddings[non_empty_indices[:, 0], non_empty_indices[:, 1]] = transformed\n",
        "\n",
        "        return output_embeddings\n",
        "\n",
        "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        batch_size = obs.shape[0]\n",
        "        ops = obs[:, :self.num_ops]\n",
        "        tree_data = obs[:, self.num_ops:]\n",
        "        tree_data = (tree_data - tree_data.min(dim=1, keepdim=True).values) / (tree_data.max(dim=1, keepdim=True).values - tree_data.min(dim=1, keepdim=True).values + 1e-8)\n",
        "\n",
        "        # Process leaf nodes separately\n",
        "        num_leaf_nodes = self.level_structure[0]['num_nodes'] if self.level_structure else (tree_data.shape[1] // self.features_per_node)\n",
        "        leaf_values = tree_data[:, -num_leaf_nodes * self.features_per_node:].view(\n",
        "            batch_size, num_leaf_nodes, self.features_per_node\n",
        "        )\n",
        "\n",
        "        leaf_embeddings = torch.zeros(batch_size, num_leaf_nodes, self.feature_dim, device=obs.device)\n",
        "\n",
        "        empty_mask = self._get_empty_mask(leaf_values)\n",
        "        if (~empty_mask).any():\n",
        "            non_empty_leaves = leaf_values[~empty_mask]\n",
        "            non_empty_indices = torch.nonzero(~empty_mask)\n",
        "\n",
        "            embeddings = self.leaf_embedding(non_empty_leaves)\n",
        "\n",
        "            level_embedding = self.level_embeddings[0].expand(len(embeddings), -1)\n",
        "            embeddings = embeddings + level_embedding\n",
        "            embeddings = self.level_norm(embeddings)\n",
        "\n",
        "            leaf_embeddings[non_empty_indices[:, 0], non_empty_indices[:, 1]] = embeddings\n",
        "\n",
        "        current_embeddings = leaf_embeddings\n",
        "\n",
        "        for level_idx, level_info in enumerate(self.level_structure):\n",
        "            current_embeddings = self.process_level(\n",
        "                level_info,\n",
        "                current_embeddings,\n",
        "                tree_data,\n",
        "                level_idx\n",
        "            )\n",
        "\n",
        "        root_embedding = current_embeddings.squeeze(1)\n",
        "        return torch.cat([root_embedding, ops], dim=1)"
      ],
      "metadata": {
        "id": "7Gp85mY_9JBP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A few helper functions for initialization\n",
        "def get_env(args: Args):\n",
        "    env = get_env_func(args)()\n",
        "    env.reset(seed=args.seed)\n",
        "    return env\n",
        "\n",
        "\n",
        "def get_env_func(args: Args):\n",
        "    def env_func():\n",
        "        env = gym.make(\"BScheduler-v0\", args=args, render_mode=None)\n",
        "        return env\n",
        "\n",
        "    return env_func\n",
        "\n",
        "\n",
        "def get_vec_env(args: Args, n_envs_override: int = None):\n",
        "    n_envs = n_envs_override or args.n_envs\n",
        "    env_func = get_env_func(args)\n",
        "    env = make_vec_env(env_func, n_envs=n_envs, vec_env_cls=DummyVecEnv)\n",
        "    return env\n",
        "\n",
        "\n",
        "def create_model(args: Args, env: BScheduler, eval_env: BScheduler):\n",
        "    print(f\"Creating model with args: {args}\")\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "\n",
        "    policy_kwargs = dict(\n",
        "        net_arch=args.s_net_arch,\n",
        "    )\n",
        "\n",
        "    if args.feature_extractor == \"tfh_fast\":  # Fast Hierarchical Transformer Feature Extractor\n",
        "        policy_kwargs['features_extractor_class'] = OptimizedHierarchicalBPlusFeatureExtractor\n",
        "        policy_kwargs['features_extractor_kwargs'] = dict(\n",
        "            feature_dim=args.s_transformer_features_dim,\n",
        "            values_per_node=args.env_max_values_per_node,\n",
        "            num_ops=args.env_num_inserts + args.env_num_deletes,\n",
        "            num_heads=args.s_transformer_nhead,\n",
        "            dropout=0.1,\n",
        "            max_levels=5,\n",
        "        )\n",
        "\n",
        "    elif args.feature_extractor == 'none':\n",
        "        print(\"Training without special feature extractor\")\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown feature_extractor: {args.feature_extractor}\")\n",
        "\n",
        "    model = MaskablePPO(\n",
        "        \"MlpPolicy\",\n",
        "        env,\n",
        "        n_epochs=args.s_n_epochs,\n",
        "        learning_rate=args.s_learning_rate,\n",
        "        verbose=1,\n",
        "        gamma=0.999,\n",
        "        device=args.device,\n",
        "        policy_kwargs=policy_kwargs,\n",
        "        seed=args.seed,\n",
        "        batch_size=args.s_batch_size,\n",
        "    )\n",
        "\n",
        "    print(\"Model policy:\", model.policy)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "vH4YkQjJ-w54"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the environment\n",
        "vec_env = get_vec_env(args)\n",
        "eval_env = get_vec_env(args, 1)\n",
        "\n",
        "# Initialize the model\n",
        "model = create_model(args, vec_env, eval_env)\n",
        "\n",
        "# Start the training process\n",
        "model.learn(total_timesteps=args.total_timesteps)\n",
        "\n",
        "# Compute the mean reward of the model for the evaluation, which can be compared to the table in the text.\n",
        "eval = evaluate_policy(model, vec_env, n_eval_episodes=1000, warn=False)\n",
        "print(\"Evaluation (mean/std):\", eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WUaSuFz2-y6f",
        "outputId": "001e6531-94c8-48ea-83b3-f48b432ebda6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model with args: <__main__.Args object at 0x7a625d172dd0>\n",
            "Using cpu device\n",
            "Model policy: MaskableActorCriticPolicy(\n",
            "  (features_extractor): OptimizedHierarchicalBPlusFeatureExtractor(\n",
            "    (transformer): TransformerEncoderLayer(\n",
            "      (self_attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (linear): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (leaf_embedding): Linear(in_features=3, out_features=64, bias=True)\n",
            "    (node_combiner): Linear(in_features=323, out_features=64, bias=True)\n",
            "    (level_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (node_norm): LayerNorm((323,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (pi_features_extractor): OptimizedHierarchicalBPlusFeatureExtractor(\n",
            "    (transformer): TransformerEncoderLayer(\n",
            "      (self_attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (linear): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (leaf_embedding): Linear(in_features=3, out_features=64, bias=True)\n",
            "    (node_combiner): Linear(in_features=323, out_features=64, bias=True)\n",
            "    (level_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (node_norm): LayerNorm((323,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (vf_features_extractor): OptimizedHierarchicalBPlusFeatureExtractor(\n",
            "    (transformer): TransformerEncoderLayer(\n",
            "      (self_attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (linear): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (leaf_embedding): Linear(in_features=3, out_features=64, bias=True)\n",
            "    (node_combiner): Linear(in_features=323, out_features=64, bias=True)\n",
            "    (level_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (node_norm): LayerNorm((323,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (mlp_extractor): MlpExtractor(\n",
            "    (policy_net): Sequential(\n",
            "      (0): Linear(in_features=76, out_features=512, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (3): Tanh()\n",
            "    )\n",
            "    (value_net): Sequential(\n",
            "      (0): Linear(in_features=76, out_features=512, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (3): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (action_net): Linear(in_features=512, out_features=12, bias=True)\n",
            "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 12       |\n",
            "|    ep_rew_mean     | -5.21    |\n",
            "| time/              |          |\n",
            "|    fps             | 2832     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 23       |\n",
            "|    total_timesteps | 65536    |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e9c301a487bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Start the training process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Compute the mean reward of the model for the evaluation, which can be compared to the table in the text.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sb3_contrib/ppo_mask/ppo_mask.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, use_masking, progress_bar)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sb3_contrib/ppo_mask/ppo_mask.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m                     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 values, log_prob, entropy = self.policy.evaluate_actions(\n\u001b[0m\u001b[1;32m    340\u001b[0m                     \u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sb3_contrib/common/maskable/policies.py\u001b[0m in \u001b[0;36mevaluate_actions\u001b[0;34m(self, obs, actions, action_masks)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maction\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_features_extractor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mlatent_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_vf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sb3_contrib/common/maskable/policies.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_features_extractor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_extractor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfeatures_extractor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \"\"\"\n\u001b[1;32m    130\u001b[0m         \u001b[0mpreprocessed_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_constructor_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-737ab293bb73>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlevel_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             current_embeddings = self.process_level(\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0mlevel_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mcurrent_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-737ab293bb73>\u001b[0m in \u001b[0;36mprocess_level\u001b[0;34m(self, level_info, current_embeddings, tree_data, level_idx)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mparent_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;31m#transformed = self.linear(parent_embeddings.unsqueeze(1)).squeeze(1) # linear version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0moutput_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnon_empty_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_empty_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    918\u001b[0m             x = self.norm1(\n\u001b[1;32m    919\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m             )\n\u001b[1;32m    922\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mis_causal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     ) -> Tensor:\n\u001b[0;32m--> 934\u001b[0;31m         x = self.self_attn(\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             )\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6228\u001b[0m             \u001b[0min_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6229\u001b[0m         ), \"use_separate_proj_weight is False but in_proj_weight is None\"\n\u001b[0;32m-> 6230\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_in_projection_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6232\u001b[0m         assert (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   5612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5613\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5614\u001b[0;31m             \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5615\u001b[0m             \u001b[0;31m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5616\u001b[0m             proj = (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}